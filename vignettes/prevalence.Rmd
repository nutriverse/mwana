---
title: "How to calculate prevalence"
output: rmarkdown::html_vignette
author: "TomÃ¡s Zaba"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
vignette: >
  %\VignetteIndexEntry{How to calculate prevalence}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE
)

library(ipccheckr)
```

## Introduction 
In this vignette, you will learn on how to use `ipccheckr` utilities to calculate acute malnutrition's prevalence. 

With `ipccheckr` you calculate acute malnutrition's prevalence based on: 

1) Weight-for-Height z-score (WFHZ) and/or edema 
2) The absolute values of Mid-Upper-arm Circumference (MUAC) and/or edema
3) Combined prevalence between WFHZ and the absolute values of MUAC and/or edema
4) MUAC-for-age z-score and/or edema

This is achieve through the use of the following functions: `compute_wfhz_prevalence()`, `compute_muac_prevalence()`, `compute_combined_prevalence()` and `compute_mfaz_prevalence()`, in the same order of appearance of the above list. I invite you to get acquainted by reading their documentation doing this: `?compute_*_prevalence()`.

These functions were carefully thought of and designed to truly simplify your workflow. For instance, 

  + If you have a data set with twenty-four areas where data was collected, you will have to compute their prevalence one-by-one then extract the results to a summary table where you collate all area's results into one table. 
  + If you are analyzing MUAC data, when you realize that the age ratio test was problematic, you are required to use another tool to re-calculate the prevalence applying an age-weighing approach. On this one, if you are unlucky and there many areas in your data set with problematic age ratio test, then you are doomed as you need to repeat the workflow several times and you quickly get tedious ðŸ˜‚ and that increases the risk of human errors ðŸ˜¬ .
  
On the other hand, not about using additional tools, sometimes you need to calculate a weighted prevalence. In current version of ENA for SMART software ( _version July 11, 2020_ ), you can only get a weighted analysis for WFHZ based prevalence, not for MUAC or combined prevalence.

With `ipccheckr` you no longer need to worry about this ðŸ¥³ as the functions are designed to deal with that. Yes, you read well, they do the standard two-stage PPS survey based sample analysis, and if you need a weighted analysis, provided that you have the survey weights, then it will also do that for you. This is possible for WFHZ, MUAC, combined and MFAZ. You will know more details in each function's section. Your task is just to call the right function, set the arguments correctly and run it. Everything else is done under the functions hood, conditionally and automatically. So, <span style="color: green;">you really do not need to worry about that</span>. 

## So, how can you use these functions? 

To demonstrate their use action, let's use different sample data sets that comes in `ipccheckr`: 

  + `anthro.02` : a survey data with survey weights. Read more about this data with `?anthro.02`.
  + `anthro.03` : a district-level SMART survey with two districts with WFHZ standard deviation classified as problematic and other not problematic.  Do `?anthro.03` for more details.
  + `anthro.04` : community-based sentinel sites. The data has different characteristics that required different analysis approaches.

Now we can begin delving into each function. Let's start with WFHZ based prevalence

### Prevalence based on WFHZ

To calculate acute malnutrition prevalence based on WFHZ you use `compute_wfhz_prevalence()` function, preceded by `process_wfhz_data()`. But first, let's inspect the `anthro.02` data. 

You do this: 
```{r wfhz.1, echo = TRUE, eval = FALSE}
tail(anthro.02)
```
This returns: 
```{r wfhz.1a, echo = FALSE}
tail(anthro.02)
```

You see that `anthro.02` has the required variables for a WFHZ prevalence, including for a weighted analysis. You may have noticed too that the data has been processed before - this was done for another purpose of this package development, but using the same data processing function `process_wfhz_data()`. Your data, however, would come in a non-processed way. If you don't how to use `process_wfhz_data()` you can check the vignette on plausibility check or do `?process_wfhz_data` in *R* console. Let's skip this step and go straight to the prevalence. Let's start with a non-weighted (or self-weighted) analysis typical of SMART surveys: 

#### Calculating a non-weighted prevalence 

To achieve this you do: 
```{r wfhz.2, echo = TRUE, eval = FALSE}

## You can approach it this way ----
compute_wfhz_prevalence(
  df = anthro.02,
  .wt = NULL,
  .edema = edema, 
  .summary_by = NULL
)

## Or you can use the pipe operator ----
anthro.02 |> 
  compute_wfhz_prevalence(
    .wt = NULL,
    .edema = edema, 
    .summary_by = NULL
    )

```

Either way, you will get this: 
```{r wfhz.2a, echo = FALSE}

compute_wfhz_prevalence(
  df = anthro.02,
  .wt = NULL,
  .edema = edema, 
  .summary_by = NULL
)
```

If for some reason, the variable edema is missing in your data, or it's there but they not plausibile and you wish to remove it from the analysis, you can give that instruction to the function to ignore `muac` in the computations. You do that by setting `.edema` to `NULL`. 

```{r wfhz.2b, echo = TRUE, eval = FALSE}

anthro.02 |> 
  compute_wfhz_prevalence(
    .wt = NULL,
    .edema = NULL,            # Setting `.edema` to `NULL`
    .summary_by = NULL
    )

```

And you get 

```{r wfhz.2c, echo = FALSE}

compute_wfhz_prevalence(
  df = anthro.02,
  .wt = NULL,
  .edema = NULL, 
  .summary_by = NULL
)
```

If you look at the `gam_n` and `gam_p` vector of the returned table in approach with edema and without edema, you see that there is a change in the numbers of these vectors. That is because in the second approach, edema was not included in case-definition, hence the prevalence. Beware that you will also see a change if there positive cases of edema in your edema variable, otherwise, if they are all negative, setting `.edema = NULL` will have no effect whatsoever. 

Now, onto another scenario, let's say your data set has multiple surveyed areas and you wish to calculate prevalence on each of them. You can easily achieve this by manipulating the `.summary_by` argument. In above examples, we set it to `NULL`. Now let's work around your wish: 

```{r wfhz.2d, echo = TRUE, eval = FALSE}
anthro.02 |> 
  compute_wfhz_prevalence(
    .wt = NULL,
    .edema = edema, 
    .summary_by = province     ## `province` is the variable's name holding data on where the survey was conducted. 
)
```

And _voila_ : 

```{r wfhz.2e, echo = FALSE}

anthro.02 |> 
  compute_wfhz_prevalence(
    .wt = NULL,
    .edema = edema, 
    .summary_by = province
)
```

A table with two rows is returned with each province's statistics.

#### Calculating a weighted prevalence 

To get a weighted prevalence, you use `.wt` argument and give to it the right variable holding the survey weights. In the case of example data set in use, the right variable is `wtfactor`. So, let's use it: 

You have to pass it in quotation `" "`

```{r wfhz.2f, echo = TRUE, eval = FALSE}
anthro.02 |> 
  compute_wfhz_prevalence(
    .wt = "wtfactor",        ## Passing the wtfactor to `.wt`
    .edema = edema, 
    .summary_by = province
)
```

And you get 

```{r wfhz.2g, echo = FALSE}

anthro.02 |> 
  compute_wfhz_prevalence(
    .wt = "wtfactor",
    .edema = edema, 
    .summary_by = province
)
```

Under the hood, before the prevalence computation starts, the function first checks the quality of WFHZ standard deviation. If it's not problematic, it proceeds to the complex sample based analysis, otherwise a calculated prevalence with standard deviation of 1 is computed instead. This is the same you get in the body of the report of the plausibility report in ENA. The `anthro.02` has no such issues, so you don't see `compute_wfhz_prevalence()` in action on this. To see that, let's use another example data set - the `anthro.03`. 

`anthro.03` has problematic standard deviation in Metuge and Maravia districts, where the remaining districts are all OK. That means you should expect and be able to spot differences between the Metuge and Maravia rows _versus_ the rest. 

Let's inspect the data

```{r wfhz.2h, echo = FALSE}
head(anthro.03)
```

Now let's apply the prevalence function

```{r wfhz.2i, echo = TRUE, eval = FALSE}
anthro.03 |> 
  process_wfhz_data(
    sex = sex,
    .recode_sex = TRUE,
    height = height,
    weight = weight
  ) |> 
  compute_wfhz_prevalence(
    .wt = NULL, 
    .edema = edema,
    .summary_by = district
  )
```

The returned output will be: 

```{r wfhz.2j, echo = FALSE}
anthro.03 |> 
  process_wfhz_data(
    sex = sex,
    .recode_sex = TRUE,
    height = height,
    weight = weight
  ) |> 
  compute_wfhz_prevalence(
    .wt = NULL, 
    .edema = edema,
    .summary_by = district
  )
```

Are you able to spot the differences ðŸ˜Ž ? Yes, you're absolutely correct. While in Cahora-Bassa and Chiuta districts all columns are filled with numbers, in Maravia and Metuge, only the columns `gam_p`, `sam_p` and `mam_p` are filled with numbers and everything else with `NA`.

### Prevalence based on MFAZ 

`compute_mfaz_prevalence()` works and is implemented the same way as `compute_wfhz_prevalence()`, except that you prepare the data with `process_age()` then `process_muac_data()` and only after that you pass to `compute_mfaz_prevalence()`. Therefore, this is intentionally not going to be demonstrated to avoid redundancy. 

### Prevalence based on MUAC 

This job is assigned to `compute_muac_prevalence()`. Once you call the function, before it starts computing the prevalence, it first starts by checking the quality of MFAZ's standard deviation and age ratio test. Yes, you read well, MFAZ's standard deviation, not on the absolute values MUAC. **However the prevalence is based on the absolute values of MUAC**. So once the standard deviation and age ratio test are checked and classified, they are used to control the prevalence computation flow as described ahead: 

  + If MFAZ's standard deviation **AND** age ratio test are <span style="color: green;">**not problematic**</span> : a standard complex sample-based prevalence is computed. 
  + If MFAZ's standard deviation is <span style="color: green;">**not problematic**</span> **BUT** age ratio test <span style="color: red;">**is problematic**</span> : an age-weighting approach is applied to fix for the likely overestimation in the prevalence due to excess of younger children. Simply put, what happens here is what you do in SMART MUAC Tool. 
  + If MFAZ's standard deviation <span style="color: red;">**is problematic**</span> **EVEN** if age ratio is not problematic: no prevalence analysis is computed, instead `NA` are thrown. 

Even if you are working on multiple survey area data set, this conditionals will still be applies according to each area's conditions. Let's see that. 

For this demonstration, let's use use `anthro.04`. 

As usual, let's first inspect it: 
```{r wfhz.3, echo = FALSE}
tail(anthro.04)
```

You see that this data has been processed already, so we can skip those steps and go straight to the prevalence. Remember that in this data, you have district adhering to each of the aforementioned situations. So you should be able to spot. 

<style>
.callout-tip {
  border-left: 4px solid #2ECC71; /* Green border */
  background-color: #EAFAF1; /* Light green background */
  padding: 10px;
  margin: 20px 0;
  border-radius: 10px;
}
</style>
<div class="callout-tip">
<strong> ðŸ’¡ Tip </strong>

You should run the plausibility check first to know about the quality of your data. If you do that with `anthro.04` you will know which province has issues, hence what you should be expecting to see in below demonstrations, based on the conditionals above stated.
</div>

```{r wfhz.3a, echo = TRUE, eval = FALSE}
anthro.04 |> 
  compute_muac_prevalence(
    .wt = NULL, 
    .edema = edema,
    .summary_by = province
  )
```

This will return: 

```{r wfhz.3b, echo = FALSE}
anthro.04 |> 
  compute_muac_prevalence(
    .wt = NULL, 
    .edema = edema,
    .summary_by = province
  )
```

You see that in `Province 1`, all columns are filled with values. In `Province 2`, some columns are filled - this is where the age-weighting approach was applied.  And in `Province 3` a bunch of `NA` are everywhere - you know why. 

#### Calculating a weighted prevalence on MUAC

For this we go back `anthro.02` data. 
You would do the following: 

```{r wfhz.3c, echo = TRUE, eval = FALSE}
library(dplyr)

anthro.02 |> 
  process_age(age = age) |> 
  process_muac_data(
    sex = sex, 
    .recode_sex = FALSE,
    muac = muac,
    .recode_muac = TRUE, 
    unit = "cm", 
    age = "age"
  ) |> 
  mutate(
    muac = recode_muac(muac, unit = "mm")
    ) |> 
  compute_muac_prevalence(
    .wt = "wtfactor", 
    .edema = edema,
    .summary_by = province
  )
```

This will return: 

```{r wfhz.3d, echo = FALSE, message=FALSE}
library(dplyr)

anthro.02 |> 
  process_age(age = age) |> 
  process_muac_data(
    sex = sex, 
    .recode_sex = FALSE,
    muac = muac,
    .recode_muac = TRUE, 
    unit = "cm", 
    age = "age"
  ) |> 
  mutate(
    muac = recode_muac(muac, unit = "mm")
    ) |> 
  compute_muac_prevalence(
    .wt = "wtfactor", 
    .edema = edema,
    .summary_by = province
  )
```


### Combined prevalence 

Combined prevalence is calculated using `compute_combined_prevalence()`. The case definition uses WFHZ, the absolute values of MUAC and edema. On the workflow standpoint, it combines `compute_wfhz_prevalence()` and `compute_muac_prevalence()`'s workflows as demonstrated below: 

Let's use `anthro.01`. 

```{r wfhz.4, echo = TRUE, eval = FALSE}
library(dplyr)

anthro.01 |> 
  process_age(
    svdate = "dos",
    birdate = "dob",
    age = age
  ) |> 
  process_muac_data(
    sex = sex, 
    .recode_sex = TRUE,
    muac = muac,
    .recode_muac = TRUE, 
    unit = "cm", 
    age = "age"
  ) |> 
  mutate(
    muac = recode_muac(muac, unit = "mm")
    ) |> 
  process_wfhz_data(
    sex = sex, 
    weight = weight,
    height = height,
    .recode_sex = FALSE
  )
```

In above code, that you are pretty much acquainted with by now, both MUAC and WFHZ data processors are used. The ultimate results of that pipeline is a data frame with `wfhz` and `flag_wfhz` and `mfaz` and `flag_mfaz`, as shown below (only these columns were selected): 

```{r wfhz.4a, echo = FALSE, message=FALSE}
library(dplyr)

anthro.01 |> 
  process_age(
    svdate = "dos",
    birdate = "dob",
    age = age
  ) |> 
  process_muac_data(
    sex = sex, 
    .recode_sex = TRUE,
    muac = muac,
    .recode_muac = TRUE, 
    unit = "cm", 
    age = "age"
  ) |> 
  mutate(
    muac = recode_muac(muac, unit = "mm")
    ) |> 
  process_wfhz_data(
    sex = sex, 
    weight = weight,
    height = height,
    .recode_sex = FALSE
  ) |> 
  select(area, wfhz, flag_wfhz, mfaz, flag_mfaz)
```

On the prevalence computation, under the hood, `compute_combined_prevalence()` applies the same exact approach used in `compute_wfhz_prevalence()` and in `compute_muac_prevalence()`, that is, checking standard deviation (of WFHZ, MFAZ), age ratio (for MUAC). In addition to this, it it creates a new vector named `cflags` for combined flags using the following case-definition: If `flag_wfhz` is `1` **OR** also `flag_mfaz` is `1`, then `cflgas` will be `1`, otherwise `0`. This ensures that all rows that flags either in WFHZ or MFAZ side are all excluded from the prevalence analysis, hence keeping consistency with non-combined prevalence's. 

Now that you understood what it does, lets see what we get when call the function: 

```{r wfhz.4b, echo = TRUE, eval = FALSE}
library(dplyr)

anthro.01 |> 
  process_age(
    svdate = "dos",
    birdate = "dob",
    age = age
  ) |> 
  process_muac_data(
    sex = sex, 
    .recode_sex = TRUE,
    muac = muac,
    .recode_muac = TRUE, 
    unit = "cm", 
    age = "age"
  ) |> 
  mutate(
    muac = recode_muac(muac, unit = "mm")
    ) |> 
  process_wfhz_data(
    sex = sex, 
    weight = weight,
    height = height,
    .recode_sex = FALSE
  ) |> 
  compute_combined_prevalence(
    .wt = NULL, 
    .edema = edema, 
    .summary_by = area
  )
```

We get this: 

```{r wfhz.4c, echo = FALSE, message=FALSE}
library(dplyr)

anthro.01 |> 
  process_age(
    svdate = "dos",
    birdate = "dob",
    age = age
  ) |> 
  process_muac_data(
    sex = sex, 
    .recode_sex = TRUE,
    muac = muac,
    .recode_muac = TRUE, 
    unit = "cm", 
    age = "age"
  ) |> 
  mutate(
    muac = recode_muac(muac, unit = "mm")
    ) |> 
  process_wfhz_data(
    sex = sex, 
    weight = weight,
    height = height,
    .recode_sex = FALSE
  ) |> 
  compute_combined_prevalence(
    .wt = NULL, 
    .edema = edema, 
    .summary_by = area
  )
```

In `District E` `NA` were returned because there were issues with the data. I leave it to you to figure out what was/were the issue/issues. 

</style>
<div class="callout-tip">
<strong> ðŸ’¡ Tip </strong>

Think of running the plausibility checkers.
</div>
